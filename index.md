---
layout: home
title: Stuart Smith CMALT Portfolio
---
## Sections
- [Contextual Statement](#Contextual-Statement)
- [Core Area 1a: Understanding the Constraints and Benefits of Different Technologies](#Core-Area-1a:-Understanding-the-Constraints-and-Benefits-of-Different-Technologies)
- [Core Area 1b: Technical Knowledge and Ability in the Use of Learning Technology](#Core-Area-1b:-Technical-Knowledge-and-Ability-in-the-Use-of-Learning-Technology)
- [Core Area 1c: Supporting the Deployment of Learning Technologies](#Core-Area-1c:-Supporting-the-Deployment-of-Learning-Technologies)
- [Core Area 2a: An Understanding of Teaching, Learning, and/or Assessment Processes](#Core-Area-2a:-An-Understanding-of-Teaching,-Learning,-and/or-Assessment-Processes)
- [Core Area 2b: An Understanding of Your Target Learners](#Core-Area-2b:-An-Understanding-of-Your-Target-Learners)
- [Core Area 3: Understanding and Engaging with Legislation, Policies, and Standards](#Core-Area-3:-Understanding-and-Engaging-with-Legislation,-Policies,-and-Standards)
- 
- 
- [Bibliography](#bibliography)
- [AI Usage Declaration](#ai-usage-declaration)
- [Credits](#credits)


## Contextual Statement
<details open>
  <summary>Expand or collapse this section</summary>
I am currently a digital skills developer at the University of Greenwich, where I lead institutional efforts to improve digital capability among students and staff. My work is grounded in the belief that learning technology is not just a set of tools, but a form of literacy essential to equity, empowerment, and future-readiness in higher education.

I have not previously completed Certified Membership of the Association for Learning Technology (CMALT), but I strongly identify with its values – particularly the commitment to exploring the interplay between technology and learning, and to supporting ethical, accessible, and inclusive practice. My Senior CMALT submission builds directly on the critical reflection and pedagogical development undertaken as part of my PGCert in Teaching in Higher Education, where I shifted from competence-based delivery to confidence-based facilitation, and began to see myself more as an educator than a technologist.

One of the cornerstones of my practice is the Digital Backpack, a university-wide initiative that I have led from inception. Designed to address widening participation, digital inclusion, and curriculum-embedded skills development, the Backpack includes a formative, confidence-based diagnostic tool aligned with both the Jisc Digital Capabilities Framework (Jisc, 2022) and the UK Government’s Essential Digital Skills Framework (Department for Education, 2019). I have led cross-departmental collaboration – including with the Moodle and branding teams – negotiated access to institutional systems, and worked directly with students to co-design inclusive interventions.

In parallel, I have overseen the integration of LinkedIn Learning using the System for Cross-domain Identity Management (SCIM) protocol, improving provisioning, segmentation, and analytics to support data-informed strategy. This work has enabled more focused engagement initiatives and greater value realisation from the institution’s investment.

I also mentor both students and staff – for example, supporting a Business School undergraduate exploring careers in learning platforms, and advising staff colleagues on digital capability development and resource design. These mentoring experiences have strengthened my commitment to developing others and fostering leadership outside formal hierarchies.

My impact spans local, institutional, and sector levels. Locally, I deliver inclusive workshops and consultations that build agency and digital confidence. Institutionally, I contribute to strategic conversations aligned with our 2030 “digital-first” vision (University of Greenwich, 2022). Sector-wide, I have spoken at events like the SHIFT Conference 2024, contribute to an internal Artificial Intelligence (AI) Special Interest Group (AI-SIG), and have helped shape guidance on the ethical use of generative AI in teaching and learning.

I also support evidence-based decision making by evaluating tools such as the Jisc Digital Capabilities Tool, LinkedIn Learning, and Microsoft Teams Premium – particularly for their AI affordances and accessibility features. These evaluations have influenced purchasing, policy, and practice at Greenwich.

This portfolio represents the next step in my professional development – from practitioner to institutional influencer. Through sustained work in learning technology, I have developed a strong strategic voice, a focus on inclusion and confidence-building, and a desire to contribute not only to my institution, but to national conversations about the ethical, inclusive, and purposeful use of digital tools in higher education.

---

### References

* Department for Education (2019) *Essential digital skills framework*. Available at: [https://www.gov.uk/government/publications/essential-digital-skills-framework](https://www.gov.uk/government/publications/essential-digital-skills-framework) (Accessed: 14 July 2025).
* Jisc (2022) *Digital Capabilities Framework: the six elements defined*. Available at: [https://digitalcapability.jisc.ac.uk/what-is-digital-capability/](https://digitalcapability.jisc.ac.uk/what-is-digital-capability/) (Accessed: 14 July 2025).
* University of Greenwich (2022) *Digital Strategy 2030: Becoming a digital-first university*. Internal document.
[↑ Back to top](#sections)
</details>

## Core Area 1a: Understanding the Constraints and Benefits of Different Technologies
<details open>
  <summary>Expand or collapse this section</summary>

### Description

As the institutional lead for LinkedIn Learning at the University of Greenwich, one of my primary responsibilities has been to ensure we derive maximum value from our investment in the platform. LinkedIn Learning offers wide-ranging skills development opportunities for both students and staff, particularly in areas such as digital literacy, employability, and personal development. However, it is a third-party platform and not directly integrated with the university’s core systems.

A key challenge we encountered was the fragmentation between LinkedIn Learning and Moodle, our primary Virtual Learning Environment (VLE). Tutors were required to manage content and learners across two systems. This led to duplicated effort, difficulties tracking student progress, and inconsistent user experiences.

To address these issues, I led the integration of LinkedIn Learning into Moodle using Learning Tools Interoperability (LTI) 1.3, enabling tutors to embed learning resources directly into their course areas. This provided a more seamless experience for students, where progress could be monitored centrally within Moodle.

This solution was evaluated against several key criteria:

* Interoperability – using an established standard that enables secure, role-aware data exchange
* Sustainability – reducing duplicate account management and making the solution scalable
* Tutor workload – simplifying access to curated content and freeing time for teaching and support
* User engagement – embedding content directly into courses encourages more consistent uptake

In parallel, I supported the adoption of the System for Cross-domain Identity Management (SCIM) protocol to automate the provisioning and de-provisioning of user accounts. SCIM allows synchronisation of role-based access using data from HR and student records systems. While Single Sign-On (SSO) supports authentication, SCIM adds granular access control and supports segmentation by audience, enabling tailored communications and learning pathways.

These choices were not without constraints. Moodle's limited support for deep linking in LTI 1.3 required significant workaround planning and the creation of support guides for tutors. The SCIM rollout required coordination across IT, HR, and third-party vendors, as well as careful alignment with internal data governance processes.

The integration has so far been piloted with a small group of tutors. While formal evaluation is still underway, initial anecdotal feedback has been positive. Tutors noted the simplicity of embedding resources and the benefit of being able to track student engagement within Moodle. Interest from professional services colleagues has also grown, particularly from HR, who are exploring LinkedIn Learning as a CPD platform for staff.

### Reflection
<details open>
  <summary>Expand or collapse this section</summary>
This project sharpened my understanding of what “fit for purpose” really means in educational technology. The most effective tools are not those with the most features, but those that integrate well into existing systems and workflows. Integration alone can fundamentally alter how a tool is perceived – transforming LinkedIn Learning from an optional resource to a valued part of the course delivery toolkit.

Initially, I underestimated how much of a barrier even small user experience issues could be. Once integration removed the friction of switching platforms, tutors became more open to engaging with LinkedIn Learning as a core teaching tool. It was a lesson in how technology decisions are only as effective as their adoption – and adoption depends on context and clarity.

This project also strengthened my skills in cross-functional collaboration. Implementing SCIM required not only technical understanding, but also communication between teams with very different priorities and vocabularies. I learned to frame technical decisions in terms of pedagogical and operational benefit, making the case for scalable, long-term solutions that are sustainable and inclusive.

Looking ahead, I am interested in exploring more advanced features of LTI and SCIM integration, including trigger-based recommendations and pathways based on learner progression. This work represents my commitment to digital systems that enable autonomy, reduce barriers, and align with wider institutional strategies for inclusive and accessible education.

---

### Evidence to be Attached

* Screenshot of LinkedIn Learning embedded within Moodle
* Diagram or summary of the SCIM provisioning workflow
* Anecdotal tutor comments or internal pilot notes
* Project documentation or planning emails
* Summary of early adoption metrics (if available)
</details>
[↑ Back to top](#sections)

## Core Area 1b: Technical Knowledge and Ability in the Use of Learning Technology
<details open>
  <summary>Expand or collapse this section</summary>

### Description

As a digital skills developer at the University of Greenwich, I apply a wide-ranging technical skill set across institutional platforms, open web technologies, and emerging AI tools. My core responsibilities include developing and embedding learning technologies that are scalable, inclusive, and strategically aligned with the university’s ambition to become a digital-first institution by 2030.

I support the creation, delivery, and integration of learning content using:

* Moodle (including Sharable Content Object Reference Model. (SCORM) packaging and plugin integration)
* Microsoft 365 (Teams, OneNote, Word, Excel, PowerPoint, OneDrive, Outlook, and Copilot)
* LinkedIn Learning, including LTI 1.3 integration for Moodle
* Custom tools for diagnostic and formative assessment – most notably the Digital Backpack

I hold a Master’s degree in Computing Science, where my dissertation focused on accessibility and Human–Computer Interaction (HCI). Earlier in my career, I contributed to Jisc-published research on accessibility in education – work that continues to influence my values-led approach to inclusive technology adoption.

As part of my ongoing professional development, I completed the ACAD-1441-M02-2024-25 Digital Teaching and Technology Enhanced Learning in Higher Education module at the University of Greenwich ([Moodle course link](https://moodlecurrent.gre.ac.uk/course/view.php?id=107625)). This course forms part of my PGCert and deepened my understanding of how learning technologies interact with pedagogical design. It also helped me stay current with sector practices, particularly in relation to accessibility, feedback, and student engagement.

### Reflection

My technical practice is rooted in the principle that accessibility is not a feature – it is a foundation. This philosophy informs both the tools I build and the formats I advocate. Structured textual formats like Markdown, semantically formatted Word documents, and HTML are not only accessible across devices and assistive technologies – they are also highly compatible with AI-powered tools like Copilot. Where learning content is structured well, tools such as Copilot are more likely to enhance clarity and engagement; where it is poorly structured, AI often compounds confusion.

In a sector increasingly dependent on multimedia and automation, I continue to champion open, portable, and inclusive design. However, I have also learned to balance idealism with pragmatism. SCORM, for example, is not the most modern standard, but its compatibility with Moodle allows me to deploy tools quickly and at scale while the institution upgrades its infrastructure.

A key example of impact is the development of the Digital Backpack capabilities assessment tool. Originally conceived as a judgement-based quiz, the tool was redesigned as a confidence-based diagnostic in direct response to feedback from colleagues across the Academic Learning Enhancement team, accessibility specialists, and digital skills practitioners. Their insight highlighted the potential for judgemental assessment models to alienate students – particularly those who lacked confidence or came from non-traditional learning backgrounds. I led the technical and pedagogical redesign to ensure the new tool was aligned with the Jisc Digital Capabilities Framework and the UK Government’s Essential Digital Skills Framework. The resulting confidence-based diagnostic now forms the basis of the university’s approach to digital skills assessment for incoming students.

This development is significant because there was previously no mechanism for diagnosing digital capability gaps at the point of entry. Given that all students are expected to engage with core digital tools from day one, the absence of diagnostic data created a serious equity issue. Without it, there was no effective way to allocate support, design inclusive interventions, or prioritise resources. By implementing the Digital Backpack as a formative, scalable tool, I have helped position it as a key institutional asset – providing a foundation for targeted upskilling, improved onboarding, and longer-term student success.

This work embodies several of the core CMALT principles: understanding the interplay between technology and learning, advocating for sustainable and inclusive practice, staying current with evolving tools, and working across professional boundaries to communicate and embed effective solutions.

---

### Evidence to be Attached

* Screenshot of SCORM content deployed in Moodle
* Description of LTI 1.3 integration and configuration
* Screenshot or annotated interface from the Digital Backpack
* Evidence of Digital Backpack usage in student induction/onboarding
* Citation or excerpt from Jisc-published accessibility research
* Confirmation or certificate of Master’s in Computing Science

</details>
[↑ Back to top](#sections)

## Core Area 1c: Supporting the Deployment of Learning Technologies

<details open>
  <summary>Expand or collapse this section</summary>

### Description

At the University of Greenwich, I play a central role in supporting the deployment of learning technologies for both students and staff. This includes not only implementing tools such as SCORM packages, LinkedIn Learning, and Microsoft Copilot, but also designing and refining systems that address institutional gaps – most notably the Digital Backpack.

The Digital Backpack was developed in response to a significant shortfall in how digital skills were assessed and supported for students entering the university. While Greenwich had previously subscribed to the Jisc Digital Capabilities Tool, its use was not embedded in a strategic or inclusive way. It also carried assumptions about user competence that made it difficult for students with limited digital experience to engage effectively.

In contrast, my approach has been to develop a tool that assumes minimal digital fluency on entry. I aligned the Digital Backpack’s capabilities assessment with both the Jisc Digital Capabilities Framework and the UK Government’s Essential Digital Skills Framework. Rather than relying on off-the-shelf solutions – which were prohibitively expensive and misaligned with our needs – I created a bespoke, confidence-based diagnostic through low-cost prototyping. This allowed me to demonstrate proof of concept and secure institutional buy-in for a tool that better meets the needs of our student population.

A significant barrier to deployment was the university’s digital strategy, which prioritises the use of existing systems. While this policy makes sense in many contexts, it did not accommodate the need for a tailored diagnostic tool that could bridge systemic gaps in digital support. By working within this constraint and proving both demand and feasibility, I was able to progress from prototype to live pilot while remaining consistent with institutional values.

### Collaboration and Impact

One of the most impactful elements of this work has been its collaborative development. I worked closely with colleagues across the Academic Learning Enhancement (ALE) team – who support academic staff development – to align our efforts. Through regular meetings and informal knowledge exchange, we identified shared goals and were able to accelerate the development of both our tools.

This collaboration led to a shared GitHub architecture, where different versions of the Digital Backpack assessment tool could be branched and adapted to suit distinct audiences. One branch now serves the ALE team’s tutor-facing needs, another supports the digital skills offer for students, and a third is under consideration for the Professional Services team to support staff induction. This branching approach supports sustainability and makes the tool flexible enough to grow with evolving institutional needs.

Beyond technical implementation, this work has started to shift how digital skills are framed at the university. By embedding the Digital Backpack in the upcoming curriculum framework, it will become a structured expectation rather than an optional add-on. Students will complete the diagnostic on arrival, enabling targeted support, early interventions, and a clearer sense of digital expectations. This cultural change – from vague digital literacy notions to clearly scaffolded digital citizenship – is one of the most significant outcomes of this deployment.

### Reflection

This experience has reaffirmed the value of open collaboration, low-cost prototyping, and values-driven development. While policy constraints initially limited solution options, I learned to work creatively within them, using institutional dialogue and pilot data to advocate for a more suitable tool.

I also gained a deeper appreciation for the diversity of learners and staff. Our student body includes individuals with little exposure to digital tools beyond passive smartphone use. Likewise, new staff arrive with highly variable digital confidence. Recognising this helped me frame digital skills not as assumed background knowledge, but as a necessary entitlement. That framing informed both the design of the tool and how I supported its rollout.

This deployment work aligns with the CMALT principles of collaboration, critical reflection, and sustainable practice. By embedding a flexible, inclusive assessment tool across departments and user groups, I have contributed to a more coherent and equitable digital experience at Greenwich – one that begins at induction and continues throughout a student’s academic journey.

---

### Evidence to be Attached

* GitHub architecture diagram showing tool branching for ALE, students, and staff
* Screenshots of Digital Backpack interface and pilot documentation
* Curriculum framework proposal referencing the Digital Backpack
* Internal correspondence with ALE and HR teams
* Institutional Digital Strategy reference (re: preference for existing systems)
* Feedback or data from pilot rollout and user testing


</details>
[↑ Back to top](#sections)

## Core Area 2a: An Understanding of Teaching, Learning, and/or Assessment Processes
<details open>
  <summary>Expand or collapse this section</summary>

### Description

As a Digital Skills Developer at the University of Greenwich, I design and deliver inclusive, scaffolded digital skills sessions that support both students and staff in developing practical capabilities. My teaching approach is grounded in constructivist, humanist, and progressivist principles. Through my PGCert in Teaching in Higher Education, I have deepened my theoretical understanding and evolved my practice to emphasise co-creation, confidence-building, and critical engagement.

### Workshop Design and Delivery

I have created a developing programme of digital skills workshops, delivered online and aligned with the university's curriculum framework. These include sessions on Copilot, Word, Excel, Outlook, Teams, OneDrive, digital wellbeing, and digital security. Importantly, these sessions are tool-agnostic. The focus is on transferable digital skills, using Microsoft 365 tools only as accessible examples of what the university provides.

Each session is carefully scaffolded: beginning with a brief introduction, followed by practical tasks based on realistic, curriculum-relevant scenarios. These tasks are chunked into manageable steps, especially in sessions that target essential digital skills. Jargon is minimised. I often describe AI interactions in natural terms – for example, replacing the word "prompt" with "question" to reduce barriers to understanding.

A notable moment came when a mature student, often bullied for their lack of digital skills, began crying during a Copilot session – not out of distress, but because they felt empowered for the first time to understand complex university systems using a tool that spoke their language. This experience reflects my core goal: to support learners not only in acquiring digital skills, but in regaining agency and confidence.

### Formative Use of AI in Learning

I explore how students can use AI tools like Copilot for formative learning – asking questions, simplifying complex university communications (such as MFA), and even reframing assessed content (within the parameters of governing institutional policies). I encourage students to treat AI as a coach, not a crutch. For example, they might use Copilot to break down a challenging question, or to generate additional examples to test their understanding. My teaching demystifies the technology and invites experimentation within ethical boundaries.

In one session, when students were given a structured task using Copilot's image creation features, they instead pursued their own creative ideas. I welcomed this divergence because the primary objective – ownership and confidence with the tool – had been achieved. My pedagogy is adaptive and responsive: I rarely know in advance who will attend, and I frequently adjust based on real-time feedback and participant needs.

### The Digital Backpack Diagnostic

The Digital Backpack confidence diagnostic tool complements this work by enabling students and staff to self-assess their digital capabilities. It draws on both the Jisc Digital Capabilities Framework and the UK Government's Essential Digital Skills Framework, offering a formative, non-judgmental entry point for digital development. Originally developed as a judgement-based skills test, we redesigned it, following feedback, as a confidence-based Likert model to avoid negative assessment experiences and better support inclusion.

It's designed for diverse users: screen-reader friendly, keyboard-navigable, and SCORM-packaged to work across platforms. It operates with a bias toward under-reporting confidence to ensure self-assessments err on the cautious side. Students receive personalised recommendations but are never explicitly told whether they are beginner, intermediate, or advanced. The goal is to promote self-efficacy and reflection, not competition or grading.

### Evolving Teaching Practice and Institutional Impact

My PGCert reflections have helped me move from "delivery" toward "facilitation." I now see my role as helping students interact meaningfully with information. I support them in exploring tools, reflecting on use, and critically evaluating output.

The university's recognition of the importance of digital skills was already evident in the creation of my role. What's evolved more recently is a shift in how those skills are approached: the confidence-first, scaffolded model that underpins the Digital Backpack is increasingly being seen as a reference point. Its inclusion in the university's developing curriculum framework reflects this. I've become a go-to person for colleagues seeking to understand how core digital capabilities intersect with the tools we use – from Microsoft 365 to generative AI. This has led to ongoing collaboration across academic and professional services teams, with my input now influencing areas beyond the traditional scope of educational development.

I draw on principles of formative and diagnostic assessment (Black & Wiliam, 1998; Sadler, 1989), treating tools like the Digital Backpack and Copilot activities as scaffolds for reflection and self-regulation rather than summative endpoints.

---

### References

Black, P., & Wiliam, D. (1998). Assessment and classroom learning. *Assessment in Education: Principles, Policy & Practice*, 5(1), 7–74. [https://doi.org/10.1080/0969595980050102](https://doi.org/10.1080/0969595980050102)

Sadler, D. R. (1989). Formative assessment and the design of instructional systems. *Instructional Science*, 18(2), 119–144. [https://doi.org/10.1007/BF00117714](https://doi.org/10.1007/BF00117714)

</details>

## Core Area 2b: An Understanding of Your Target Learners
<details open>
  <summary>Expand or collapse this section</summary>

### Description

My work as a Digital Skills Developer at the University of Greenwich is framed by the institution’s strategic aim to become a digital-first university by 2030. This ambition places digital capability development at the heart of teaching and learning across all disciplines. Within this wider context, my work on the Digital Backpack initiative and associated AI workshops is designed to align not only with institutional priorities but also with key national frameworks and sector-wide conversations on digital equity, confidence, and inclusion.

### Digital Backpack as a Strategic and Sector-Aligned Tool

The Digital Backpack serves as a formative confidence-based diagnostic tool, mapping to both the Jisc Digital Capabilities Framework and the UK Government’s Essential Digital Skills Framework. It enables students and staff to reflect on their own digital competencies, receive personalised feedback, and engage in scaffolded learning journeys.

This tool supports the university’s commitment to inclusive access and life-wide digital literacy. It allows us to surface inequalities in digital confidence while avoiding the punitive tone of traditional assessment. In a sector context, the Digital Backpack represents a scalable response to national calls for more inclusive and responsive digital skills strategies.

### Widening Participation and Digital Inclusion

The tool and workshops are built with a strong commitment to inclusion. Students from diverse linguistic, cultural, and socio-economic backgrounds regularly attend our sessions with vastly different digital starting points. Some may be confident consumers of social media but lack productive or academic digital skills.

By focusing on non-judgmental self-assessment, plain language, and tool-agnostic tasks, the Backpack encourages a sense of agency and confidence. My reflection on delivering these sessions is that digital skills equity is not simply about access to tools, but about pedagogy and approach – how we frame digital development so it feels empowering rather than remedial.

### AI, Critical Thinking, and Institutional Adaptation

My AI-focused workshops introduce students and staff to Microsoft Copilot and guide them through its use as a formative learning companion. Informed by my PGCert study and institutional policy involvement, I teach participants how to critically use generative AI to:

* Reframe complex questions
* Generate model answers or revision materials
* Translate and simplify academic language
* Test their understanding through example generation

This work reflects a wider shift in higher education. According to Intelligent.com (2024), 92% of students report using generative AI tools. The majority of this use happens outside guided learning. By embedding critical AI practice in our workshops, I aim to close the gap between informal use and educational benefit.

I have contributed to the development of our university’s AI guidance and emphasise the importance of transparency, data awareness, and academic integrity in all AI-based activities.

### Understanding Learner Needs and Evolving Practice

Understanding the needs of learners in a digital-first institution has required both responsive design and creative feedback mechanisms. In live workshops, I have increasingly shifted from traditional knowledge checks (e.g. “Do you know how to…?”) toward interactive confidence-based sliders, particularly using tools like Mentimeter. These help surface not just gaps in capability, but underlying anxieties and misconceptions, especially for students who are reluctant to speak or appear on camera during online sessions.

To supplement this, I regularly liaise with experienced colleagues who teach more directly and who have built long-term relationships with cohorts. Their insights have helped me shape materials and teaching approaches that are more culturally and linguistically responsive. This triangulated input – from students, peers, and real-time analytics – allows me to adapt delivery dynamically.

One example of changed practice is the development of short, 10–15 minute presentation scripts that can be delivered live or accessed asynchronously. These are used to introduce a concept or digital skill before opening into collaborative exploration or tool-based tasks. This model accommodates different learning paces while maximising limited contact time. It also provides flexibility for learners who may never attend workshops but still need access to accessible, scaffolded content.

The introduction of Microsoft Copilot and other AI tools into the student learning environment has also led to a major shift in my approach. I now include AI literacy in nearly every session – not only to acknowledge how widely students already use tools like ChatGPT, but to actively teach ethical and critical practices. By giving explicit permission to explore generative AI tools within defined boundaries, I help students shift from passive consumption to active, reflective engagement with both their learning content and the technology itself.

### Reflection and Sector Engagement

The wider context is changing rapidly, and while tools like Copilot offer powerful affordances, our assessment models and institutional practices often lag behind. I believe AI represents a levelling force – particularly for neurodivergent learners, mature students, and multilingual users – but only if pedagogy evolves alongside it.

Through the Digital Backpack and AI teaching, I advocate for infrastructure and practice that acknowledges difference, prioritises confidence, and respects autonomy. My future goals include continued refinement of the diagnostic approach, further involvement in AI policy, and sharing of practice across the sector to support inclusive digital transformation.

---

### To-Do List for Evidence

* Add artefact e.g student quote

### References

Intelligent.com (2024) *Survey: 92% of college students use AI tools like ChatGPT*. Available at: [https://www.intelligent.com/](https://www.intelligent.com/) (Accessed: 14 July 2025).

Jisc (no date) *Digital capabilities framework*. Available at: [https://jisc.ac.uk](https://jisc.ac.uk) (Accessed: 14 July 2025).

UK Department for Education (2019) *Essential digital skills framework*. Available at: [https://www.gov.uk/government/publications/essential-digital-skills-framework](https://www.gov.uk/government/publications/essential-digital-skills-framework) (Accessed: 14 July 2025).


</details>



* [ ] Copy of Digital Backpack mapping documentation (to Jisc/Essential Digital Skills)

* [ ] Screenshot or link to university AI policy showing contributed definition

* [ ] Email or notes showing contribution to LinkedIn Learning or Teams Premium rollout

* [ ] Evidence of WCAG 2.1 compliance checklists used in workshop/resource development

* [ ] Meeting minutes or summary of AI SIG discussions reflecting your input

*

---

### References

Equality Act 2010. (2010) *legislation.gov.uk*. Available at: [https://www.legislation.gov.uk/ukpga/2010/15/contents](https://www.legislation.gov.uk/ukpga/2010/15/contents) (Accessed: 14 July 2025).

European Union (2016) *Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 (General Data Protection Regulation)*. Available at: [https://gdpr.eu/](https://gdpr.eu/) (Accessed: 14 July 2025).

UK Government (2018) *The Public Sector Bodies (Websites and Mobile Applications) Accessibility Regulations 2018*. Available at: [https://www.legislation.gov.uk/uksi/2018/952/contents/made](https://www.legislation.gov.uk/uksi/2018/952/contents/made) (Accessed: 14 July 2025).

UK Department for Education (2019) *Essential digital skills framework*. Available at: [https://www.gov.uk/government/publications/essential-digital-skills-framework](https://www.gov.uk/government/publications/essential-digital-skills-framework) (Accessed: 14 July 2025).

Jisc (no date) *Digital capabilities framework*. Available at: [https://www.jisc.ac.uk/rd/projects/building-digital-capability](https://www.jisc.ac.uk/rd/projects/building-digital-capability) (Accessed: 14 July 2025).

University of Greenwich (no date) *AI Guidance for Research*. Available at: [https://www.gre.ac.uk/ai-guidance/research](https://www.gre.ac.uk/ai-guidance/research) (Accessed: 14 July 2025).

Equality Act 2010. (2010) *legislation.gov.uk*. Available at: [https://www.legislation.gov.uk/ukpga/2010/15/contents](https://www.legislation.gov.uk/ukpga/2010/15/contents) (Accessed: 14 July 2025).

European Union (2016) *Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 (General Data Protection Regulation)*. Available at: [https://gdpr.eu/](https://gdpr.eu/) (Accessed: 14 July 2025).

UK Government (2018) *The Public Sector Bodies (Websites and Mobile Applications) Accessibility Regulations 2018*. Available at: [https://www.legislation.gov.uk/uksi/2018/952/contents/made](https://www.legislation.gov.uk/uksi/2018/952/contents/made) (Accessed: 14 July 2025).

UK Department for Education (2019) *Essential digital skills framework*. Available at: [https://www.gov.uk/government/publications/essential-digital-skills-framework](https://www.gov.uk/government/publications/essential-digital-skills-framework) (Accessed: 14 July 2025).

Jisc (no date) *Digital capabilities framework*. Available at: [https://www.jisc.ac.uk/rd/projects/building-digital-capability](https://www.jisc.ac.uk/rd/projects/building-digital-capability) (Accessed: 14 July 2025).


</details>

## Core Area 3: Understanding and Engaging with Legislation, Policies, and Standards
<details open>
  <summary>Expand or collapse this section</summary>

### Description

My work in digital education requires a strong awareness of both legal and policy contexts. I regularly navigate legislative frameworks such as the General Data Protection Regulation (GDPR), accessibility requirements under the Equality Act 2010, and the UK’s copyright and licensing laws. These shape not only how I develop and deliver digital content, but also how I advise colleagues and guide institutional decisions. In addition to legal compliance, I engage with internal policies and national frameworks that influence practice in digital learning, inclusion, and AI ethics.

---

### 3a: Understanding and Engaging with Legislation

A key legislative consideration in my role is the handling of student data and analytics, particularly as it relates to personalised learning and diagnostic tools. For example, the Digital Backpack project collects learner confidence data through a SCORM-based diagnostic, which only stored in a university approved system (Moodle). While we did not liaise directly with the Data Protection Office, we followed the university’s published data protection guidance closely and applied best practice under GDPR. One of our key principles is that we do not collect or retain any data that is not needed. All diagnostic data remains within Moodle, which has already been assessed and approved by the university. Students are invited to download a PDF of their results for personal use, but this is not retained on our systems, and the data disappears after download.

Although the data collected is low-risk, we recognise the sensitivity of confidence scores and have been careful to ensure that the platform and associated processes align with policy frameworks. This approach reflects our belief in privacy by design and data minimisation.

My experience with GDPR also extends to my early work on the LinkedIn Learning rollout. There was confusion at the university regarding whether users were required to link their personal LinkedIn profiles to their university accounts. I identified this issue and worked to revise internal documentation to clarify that linking is optional. This interpretation was later endorsed by the Data Protection Officer, reinforcing the importance of clarity and transparency in GDPR compliance.

Over time, my thinking on compliance has evolved, particularly in response to the rise of generative AI. The rapid adoption of tools like Copilot has made it clear that AI policies need to be carefully worded. I advocated early on for precision in university policy language to ensure we don’t apply blanket terms to a highly complex and diverse set of technologies. As a result, I contributed to internal policy documents that distinguish between types of AI and the contexts in which they may or may not be used.

I have become increasingly concerned about the limitations of current licensing models, particularly with Copilot. For instance, the university’s current implementation uses a corporate version of Microsoft 365 Copilot, which has notable content censorship and filtering that could limit academic research or open inquiry. While suitable in some contexts, such restrictions are problematic in a university setting, where academic freedom and open access to controversial or sensitive topics are essential.

I have used my role within the university’s AI Special Interest Group (SIG) to reflect on and share these concerns, particularly around the disparity this might create between departments. For example, an AI tool acceptable in business or marketing courses may be completely unworkable in research exploring health, politics, or gender studies. These unresolved tensions inform my view that higher education institutions must push for purpose-built AI tools that respect both legal boundaries and academic needs.

I have also raised concerns about the digital divide created when AI tools that level the playing field for disadvantaged students are restricted. Private tuition and access to cultural capital are rarely challenged, yet tools like GPT and Copilot are often viewed with suspicion. I have contributed to ongoing internal work on generative AI guidance to ensure that equity, access, and ethical use are all embedded in our institutional response.

While I have no final resolution to the tensions raised by AI licensing and censorship, I believe ongoing dialogue and policy clarity are critical. I continue to advocate for a higher education-specific licensing model that supports safe, inclusive, and critical engagement with generative AI technologies.

My understanding of the legal landscape has also informed the responsible adoption of Microsoft Copilot and LinkedIn Learning. For example, I have raised concerns about platform data use, the terms of service, and the lack of institutional control over some AI outputs. In doing so, I contributed to our internal AI guidance, which stresses transparency, learner consent, and alignment with UK GDPR principles.

I also consider accessibility legislation—particularly the Public Sector Bodies (Websites and Mobile Applications) Accessibility Regulations 2018—in every tool or learning resource I design. My background in Human–Computer Interaction and accessibility, including postgraduate work and Jisc-published research, has embedded this deeply in my practice.

---

### 3b: Understanding and Engaging with Policies and Standards

I have played an active role in shaping institutional strategy and policy, particularly in the areas of digital capability and generative AI. One significant example is the integration of the Digital Backpack into the university’s curriculum framework. This required working closely with the Academic Learning Enhancement (ALE) team and aligning the tool with institutional graduate attributes. I authored documentation mapping Backpack content to both the Jisc and Essential Digital Skills frameworks to support this integration.

I also engage regularly with technical standards and procurement processes. When rolling out platforms such as LinkedIn Learning and piloting Teams Premium, I assessed compliance with WCAG 2.1 AA accessibility guidelines and ensured the solutions met our institutional interoperability standards, including SCORM and LTI 1.3. I contributed to procurement and onboarding documentation to ensure alignment with technical, pedagogical, and ethical priorities.

In the area of generative AI, I am a member of the University’s AI Special Interest Group (SIG), where I actively contribute to discussions and documentation. Notably, I directly contributed to the official university AI guidance for research by helping define 'generative AI' and advocating the adoption of IBM’s definition, which has since been published as part of the university’s policy (University of Greenwich, no date). My advocacy in this space has consistently focused on precision in language to ensure AI guidance reflects the wide range of tools and use cases, rather than applying restrictive blanket terms.

These experiences have deepened my understanding of the challenge in translating abstract values like inclusivity, transparency, and equity into practice. As an example, my work has helped shape how university policies address the limitations of commercial AI licenses, particularly the content filtering built into corporate versions of Copilot. I have raised concerns through the AI SIG that these constraints may disproportionately affect research areas that explore sensitive or marginalised topics. This reflection continues to shape how I engage with policy – advocating for clarity, nuance, and above all, equitable implementation.

Overall, I see policy not as a constraint but as a living tool that can support responsible innovation when approached with care and critical thought.

I also work within and promote adherence to standards of interoperability (e.g. SCORM and LTI 1.3) and accessibility (e.g. WCAG 2.1 AA). These standards guide my decisions when selecting tools or proposing integrations—ensuring both student access and sustainability. For example, during the rollout of LinkedIn Learning and the Teams Premium pilot, I assessed their compliance with technical and ethical standards and contributed documentation to support procurement and staff onboarding.

Finally, I participate in university working groups and Special Interest Groups (SIGs) where policies on generative AI, accessibility, and digital equity are discussed. My input often centres on how to translate high-level policies into implementable, inclusive practices. I aim to ensure that policies do not just exist in principle but actually support meaningful change in practice.

---

### To-Do List for Evidence

* [ ] Copy of Digital Backpack mapping documentation (to Jisc/Essential Digital Skills)

* [ ] Screenshot or link to university AI policy showing contributed definition

* [ ] Email or notes showing contribution to LinkedIn Learning or Teams Premium rollout

* [ ] Evidence of WCAG 2.1 compliance checklists used in workshop/resource development

* [ ] Meeting minutes or summary of AI SIG discussions reflecting your input

*

---

### References

Equality Act 2010. (2010) legislation.gov.uk. Available at: https://www.legislation.gov.uk/ukpga/2010/15/contents (Accessed: 14 July 2025).

European Union (2016) Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 (General Data Protection Regulation). Available at: https://gdpr.eu/ (Accessed: 14 July 2025).

UK Government (2018) The Public Sector Bodies (Websites and Mobile Applications) Accessibility Regulations 2018. Available at: https://www.legislation.gov.uk/uksi/2018/952/contents/made (Accessed: 14 July 2025).

UK Department for Education (2019) Essential digital skills framework. Available at: https://www.gov.uk/government/publications/essential-digital-skills-framework (Accessed: 14 July 2025).

Jisc (no date) Digital capabilities framework. Available at: https://www.jisc.ac.uk/rd/projects/building-digital-capability (Accessed: 14 July 2025).

University of Greenwich (no date) AI Guidance for Research. Available at: https://www.gre.ac.uk/ai-guidance/research (Accessed: 14 July 2025).
</details>

## Hold 2
<details open>
  <summary>Expand or collapse this section</summary>


</details>
[↑ Back to top](#sections)
## Bibliography

- Advance HE. (2023) *Professional Standards Framework for teaching and supporting learning in higher education 2023*. Available at: https://s3.eu-west-2.amazonaws.com/assets.creode.advancehe-document-manager/documents/advance-he/PSF%202023%20-%20Screen%20Reader%20Compatible%20-%20final_1675089549.pdf (Accessed: 20 May 2025).

- Field, H. (2024) ‘Microsoft is blocking terms that cause its AI to create violent images’, *CNBC*. Available at: https://www.cnbc.com/2024/03/08/microsoft-blocking-terms-that-cause-its-ai-to-create-violent-images.html (Accessed: 20 May 2025).

- Forster, E. M. (1928) *The Machine Stops*. Available at: https://www.ele.uri.edu/faculty/vetter/Other-stuff/The-Machine-Stops.pdf (Accessed: 20 May 2025).

- Jisc. (2019) *Building Digital Capability: The six elements defined*. Available at: https://www.jisc.ac.uk/rd/projects/building-digital-capability (Accessed: 20 May 2025).

- Knox, J. (2020) ‘Artificial intelligence and education in China’, *Learning, Media and Technology*, 45(3), pp. 295–308. https://doi.org/10.1080/17439884.2020.1740652

- Oelen, A. and Auer, S. (2019) ‘Content authoring with Markdown for visually impaired and blind users’, in *Proceedings of the 16th International Web for All Conference*. New York: ACM, pp. 1–10. https://doi.org/10.1145/3315002.3317576

- Rogers, C. R. (1969) *Freedom to Learn*. Columbus, OH: Merrill.

- Selwyn, N. (2019) *Should Robots Replace Teachers? AI and the Future of Education*. Cambridge: Polity Press.

- Smith, S. M. (2001) *Can a Virtual Learning Environment Interface Meet the Needs of Dyslexics and Non-Dyslexics?* MSc dissertation. Staffordshire University.

- Smith, S. M. (2002) ‘Dyslexia and virtual learning environment interfaces’, in *Access All Areas: Disability, Technology and Learning*. Staffordshire University, pp. 50–53.

- University of Greenwich. (2021) *University of Greenwich Strategy 2030*. Available at: https://www.gre.ac.uk/__data/assets/pdf_file/0034/287953/uog-strategy.pdf (Accessed: 20 May 2025).

- Vygotsky, L. S. (1978) *Mind in Society: The Development of Higher Psychological Processes*. Cambridge, MA: Harvard University Press.

- Zhao, W., Yang, M., Zhang, H., Liu, Y., and Chen, H. (2025) ‘Let AI read first: Enhancing reading abilities for individuals with dyslexia through artificial intelligence’, *arXiv*. Available at: https://arxiv.org/abs/2504.00941 (Accessed: 20 May 2025).

[↑ Back to top](#sections)


## AI Usage Declaration

- To develop research questions on the topic – YES
- To create an outline of the topic – YES
- To explain concepts – YES
- To support my use of language – NO
- To summarise the following resources:
  - [https://www.jisc.ac.uk/rd/projects/building-digital-capability](https://www.jisc.ac.uk/rd/projects/building-digital-capability)
  - [https://www.cnbc.com/2024/03/08/microsoft-blocking-terms-that-cause-its-ai-to-create-violent-images.html](https://www.cnbc.com/2024/03/08/microsoft-blocking-terms-that-cause-its-ai-to-create-violent-images.html)
  - Oelen, A. and Auer, S. (2019) ‘Content Authoring with Markdown for Visually Impaired and Blind Users
  
  [↑ Back to top](#sections)

## Credits

- Photo by Stuart Smith (personal collection)
- Photo by John Barkiple on Unsplash
- Photo by Yle Archives on Unsplash
- Photo by Peter John Maridable on Unsplash
- Photo by Gerard Siderius on Unsplash
- Photo by Fotis Fotopoulos on Unsplash
- Photo by Seema Miah on Unsplash

[↑ Back to top](#sections)